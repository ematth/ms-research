{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as tf\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from model import CRNN_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for loading in dataset\n",
    "\n",
    "import pandas as pd\n",
    "class BachDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file: str, root_dir: str):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file.\n",
    "            root_dir (string): Directory with all the images.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(root_dir + csv_file)\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int = 0):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        print(self.root_dir + f'invent{idx+1}32-page1.png')\n",
    "        img = torchvision.io.read_image(self.root_dir + f'invent{idx+1}32-page1.png')\n",
    "        ly_list= []\n",
    "        with open(self.root_dir + f'invent{idx+1}32.ly', 'r') as file:\n",
    "            ly_list.append(file.read().replace('\\n', ' ').split(' '))\n",
    "        \n",
    "        sample = {'img': img, 'ly': ly_list}\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_parse import quant_parse\n",
    "\n",
    "# Data normalization: get optimal quantization (1, 2, 4, 8, 16, 32) from .ly file.\n",
    "# This has been done pre-training, but this block shows what code was run:\n",
    "\"\"\"\n",
    "for i in range(1, 16):\n",
    "    q = quant_parse(i)\n",
    "    print(q)\n",
    "\"\"\"\n",
    "\n",
    "# Optimal Quantization was used as a parameter in convert.sh for data normalization.\n",
    "\n",
    "q = quant_parse(2)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_dir = 'outputs/bach/invent/'\n",
    "\n",
    "trainset = BachDataset(csv_file='dataset.csv', root_dir=root_dir)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer \n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "net = CRNN_Network(128)\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop for CNN\n",
    "def train(crnn: CRNN_Network, criterion: torch.nn.Module, optimizer: torch.optim.Optimizer, num_epochs: int):\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        running_loss: float = 0.\n",
    "\n",
    "        for i, (img, ly) in trainloader:\n",
    "            images, lys = img, ly\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = crnn(images)\n",
    "            loss = criterion(outputs, lys)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # predicted = torch.argmax(outputs, 1).to(device)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            print_freq = 100\n",
    "            if i % print_freq == (print_freq - 1):\n",
    "                print(f'[{e + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100 * running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
    "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
    "                start_time = time.time()\n",
    "\n",
    "    print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 45\n",
    "train(net, criterion, optimizer, num_epochs)\n",
    "torch.save(net.state_dict(), f\"./model-ep{num_epochs}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
